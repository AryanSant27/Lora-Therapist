# Lora-Therapist
Meet Lora - Your Own Therapist, a fine-tuned LLM on the data-set of therapy sessions. It uses Parameter Efficient fine tuning (PEFT). Using Low Rank Adaptation where we only train a particular number of parameters, we trained Meta Llama 7b on Tesla T4 GPU. The dataset can be found on HuggingFace.


You can find the adapters at [aryan27/llama-therapy-lora](https://huggingface.co/aryan27/llama-therapy-lora)

You will also find the model card which demonstrates how to use the model with its adapters.
